{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMosKud3Vcz2WKO7FntJzhI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucianoon/1/blob/main/Lang.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "5wlBGz5PgMEX",
        "outputId": "4f79f9d0-603c-402c-adbf-267236fe8e7c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain_community'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2308178745>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdataclasses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdataclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConversationBufferWindowMemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHumanMessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAIMessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSystemMessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chat_models/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_community\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mchat_models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# If not in interactive env, raise warning.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_community'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import os\n",
        "import logging\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Optional\n",
        "from dataclasses import dataclass\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
        "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
        "from langchain.tools import Tool\n",
        "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Configuração de logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "@dataclass\n",
        "class CustomerInfo:\n",
        "    \"\"\"Informações do cliente\"\"\"\n",
        "    customer_id: str\n",
        "    name: str\n",
        "    email: str\n",
        "    phone: str\n",
        "    tier: str  # \"bronze\", \"silver\", \"gold\", \"platinum\"\n",
        "\n",
        "class KnowledgeBase:\n",
        "    \"\"\"Base de conhecimento para consultas\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.vectorstore = None\n",
        "        self.embeddings = OpenAIEmbeddings()\n",
        "\n",
        "    def load_knowledge_base(self, file_path: str):\n",
        "        \"\"\"Carrega a base de conhecimento de um arquivo\"\"\"\n",
        "        try:\n",
        "            loader = TextLoader(file_path, encoding='utf-8')\n",
        "            documents = loader.load()\n",
        "\n",
        "            text_splitter = RecursiveCharacterTextSplitter(\n",
        "                chunk_size=1000,\n",
        "                chunk_overlap=200\n",
        "            )\n",
        "            texts = text_splitter.split_documents(documents)\n",
        "\n",
        "            self.vectorstore = FAISS.from_documents(texts, self.embeddings)\n",
        "            logger.info(f\"Base de conhecimento carregada com {len(texts)} documentos\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Erro ao carregar base de conhecimento: {e}\")\n",
        "\n",
        "    def search(self, query: str, k: int = 3) -> List[str]:\n",
        "        \"\"\"Busca informações na base de conhecimento\"\"\"\n",
        "        if not self.vectorstore:\n",
        "            return [\"Base de conhecimento não carregada\"]\n",
        "\n",
        "        try:\n",
        "            docs = self.vectorstore.similarity_search(query, k=k)\n",
        "            return [doc.page_content for doc in docs]\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Erro na busca: {e}\")\n",
        "            return [\"Erro ao buscar informações\"]\n",
        "\n",
        "class CustomerServiceAgent:\n",
        "    \"\"\"Agente de atendimento ao cliente com LangChain\"\"\"\n",
        "\n",
        "    def __init__(self, openai_api_key: str):\n",
        "        os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "\n",
        "        # Inicializar componentes\n",
        "        self.llm = ChatOpenAI(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            temperature=0.7,\n",
        "            max_tokens=500\n",
        "        )\n",
        "\n",
        "        self.memory = ConversationBufferWindowMemory(\n",
        "            k=10,\n",
        "            memory_key=\"chat_history\",\n",
        "            return_messages=True\n",
        "        )\n",
        "\n",
        "        self.knowledge_base = KnowledgeBase()\n",
        "        self.current_customer: Optional[CustomerInfo] = None\n",
        "\n",
        "        # Configurar ferramentas\n",
        "        self.tools = self._create_tools()\n",
        "\n",
        "        # Configurar prompt do agente\n",
        "        self.prompt = self._create_prompt()\n",
        "\n",
        "        # Criar agente\n",
        "        self.agent = create_openai_functions_agent(\n",
        "            llm=self.llm,\n",
        "            tools=self.tools,\n",
        "            prompt=self.prompt\n",
        "        )\n",
        "\n",
        "        self.agent_executor = AgentExecutor(\n",
        "            agent=self.agent,\n",
        "            tools=self.tools,\n",
        "            memory=self.memory,\n",
        "            verbose=True,\n",
        "            max_iterations=3\n",
        "        )\n",
        "\n",
        "    def _create_tools(self) -> List[Tool]:\n",
        "        \"\"\"Cria as ferramentas disponíveis para o agente\"\"\"\n",
        "\n",
        "        def search_knowledge_base(query: str) -> str:\n",
        "            \"\"\"Busca informações na base de conhecimento\"\"\"\n",
        "            results = self.knowledge_base.search(query)\n",
        "            return \"\\n\\n\".join(results)\n",
        "\n",
        "        def get_customer_info(customer_id: str) -> str:\n",
        "            \"\"\"Obtém informações do cliente\"\"\"\n",
        "            # Simulação - em produção seria uma consulta ao banco de dados\n",
        "            customers_db = {\n",
        "                \"12345\": CustomerInfo(\"12345\", \"João Silva\", \"joao@email.com\", \"(11) 99999-9999\", \"gold\"),\n",
        "                \"67890\": CustomerInfo(\"67890\", \"Maria Santos\", \"maria@email.com\", \"(11) 88888-8888\", \"silver\")\n",
        "            }\n",
        "\n",
        "            customer = customers_db.get(customer_id)\n",
        "            if customer:\n",
        "                self.current_customer = customer\n",
        "                return f\"Cliente: {customer.name}\\nEmail: {customer.email}\\nTelefone: {customer.phone}\\nNível: {customer.tier}\"\n",
        "            return \"Cliente não encontrado\"\n",
        "\n",
        "        def escalate_to_human(reason: str) -> str:\n",
        "            \"\"\"Escala o atendimento para um atendente humano\"\"\"\n",
        "            logger.info(f\"Escalação solicitada: {reason}\")\n",
        "            return f\"Atendimento escalado para humano. Motivo: {reason}. Um atendente entrará em contato em breve.\"\n",
        "\n",
        "        def check_order_status(order_id: str) -> str:\n",
        "            \"\"\"Consulta status do pedido\"\"\"\n",
        "            # Simulação - em produção seria uma consulta ao sistema de pedidos\n",
        "            orders_db = {\n",
        "                \"ORD001\": {\"status\": \"Em trânsito\", \"tracking\": \"BR123456789\", \"delivery_date\": \"2024-01-15\"},\n",
        "                \"ORD002\": {\"status\": \"Entregue\", \"tracking\": \"BR987654321\", \"delivery_date\": \"2024-01-10\"}\n",
        "            }\n",
        "\n",
        "            order = orders_db.get(order_id)\n",
        "            if order:\n",
        "                return f\"Pedido {order_id}: {order['status']}\\nCódigo de rastreamento: {order['tracking']}\\nPrevisão de entrega: {order['delivery_date']}\"\n",
        "            return \"Pedido não encontrado\"\n",
        "\n",
        "        return [\n",
        "            Tool(\n",
        "                name=\"search_knowledge_base\",\n",
        "                description=\"Busca informações na base de conhecimento da empresa\",\n",
        "                func=search_knowledge_base\n",
        "            ),\n",
        "            Tool(\n",
        "                name=\"get_customer_info\",\n",
        "                description=\"Obtém informações do cliente usando o ID do cliente\",\n",
        "                func=get_customer_info\n",
        "            ),\n",
        "            Tool(\n",
        "                name=\"escalate_to_human\",\n",
        "                description=\"Escala o atendimento para um atendente humano quando necessário\",\n",
        "                func=escalate_to_human\n",
        "            ),\n",
        "            Tool(\n",
        "                name=\"check_order_status\",\n",
        "                description=\"Consulta o status de um pedido usando o ID do pedido\",\n",
        "                func=check_order_status\n",
        "            )\n",
        "        ]\n",
        "\n",
        "    def _create_prompt(self) -> ChatPromptTemplate:\n",
        "        \"\"\"Cria o prompt do agente\"\"\"\n",
        "        system_message = \"\"\"Você é um assistente virtual de atendimento ao cliente altamente qualificado e empático.\n",
        "\n",
        "INSTRUÇÕES:\n",
        "- Seja sempre cordial, profissional e prestativo\n",
        "- Use linguagem clara e acessível\n",
        "- Mantenha o foco na resolução do problema do cliente\n",
        "- Se não souber a resposta, use as ferramentas disponíveis ou escale para um humano\n",
        "- Sempre confirme informações importantes com o cliente\n",
        "- Personalize o atendimento baseado no perfil do cliente\n",
        "\n",
        "QUANDO ESCALAR PARA HUMANO:\n",
        "- Reclamações complexas ou sensíveis\n",
        "- Solicitações de reembolso acima de R$ 500\n",
        "- Problemas técnicos que não consegue resolver\n",
        "- Cliente expressamente solicita falar com humano\n",
        "- Situações que exigem tomada de decisão gerencial\n",
        "\n",
        "FERRAMENTAS DISPONÍVEIS:\n",
        "- search_knowledge_base: Para buscar informações sobre produtos, políticas, etc.\n",
        "- get_ customer_info: Para obter dados do cliente\n",
        "- escalate_to_human: Para transferir para atendente humano\n",
        "- check_order_status: Para consultar status de pedidos\n",
        "\n",
        "Hora atual: {current_time}\n",
        "\"\"\"\n",
        "\n",
        "        return ChatPromptTemplate.from_messages([\n",
        "            (\"system\", system_message),\n",
        "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "            (\"human\", \"{input}\"),\n",
        "            MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
        "        ])\n",
        "\n",
        "    def load_knowledge_base(self, file_path: str):\n",
        "        \"\"\"Carrega a base de conhecimento\"\"\"\n",
        "        self.knowledge_base.load_knowledge_base(file_path)\n",
        "\n",
        "    def chat(self, message: str) -> str:\n",
        "        \"\"\"Processa uma mensagem do cliente\"\"\"\n",
        "        try:\n",
        "            current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "            # Adiciona contexto do cliente se disponível\n",
        "            context = \"\"\n",
        "            if self.current_customer:\n",
        "                context = f\"\\nCliente atual: {self.current_customer.name} (Nível: {self.current_customer.tier})\"\n",
        "\n",
        "            response = self.agent_executor.invoke({\n",
        "                \"input\": message + context,\n",
        "                \"current_time\": current_time\n",
        "            })\n",
        "\n",
        "            return response[\"output\"]\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Erro no processamento: {e}\")\n",
        "            return \"Desculpe, ocorreu um erro interno. Vou transferir você para um atendente humano.\"\n",
        "\n",
        "    def reset_conversation(self):\n",
        "        \"\"\"Reinicia a conversa\"\"\"\n",
        "        self.memory.clear()\n",
        "        self.current_customer = None\n",
        "        logger.info(\"Conversa reiniciada\")\n",
        "\n",
        "# Exemplo de uso\n",
        "def main():\n",
        "    # Configurar chave da API OpenAI\n",
        "    API_KEY = \"sua-chave-openai-aqui\"\n",
        "\n",
        "    # Criar agente\n",
        "    agent = CustomerServiceAgent(API_KEY)\n",
        "\n",
        "    # Exemplo de base de conhecimento (criar arquivo knowledge_base.txt)\n",
        "    knowledge_content = \"\"\"\n",
        "    POLÍTICA DE TROCA E DEVOLUÇÃO:\n",
        "    - Prazo: 30 dias corridos a partir da data de recebimento\n",
        "    - Produto deve estar em perfeitas condições\n",
        "    - Embalagem original deve estar preservada\n",
        "    - Taxa de reenvio por conta do cliente (exceto defeito de fabricação)\n",
        "\n",
        "    FORMAS DE PAGAMENTO ACEITAS:\n",
        "    - Cartão de crédito (Visa, Mastercard, Elo)\n",
        "    - Cartão de débito\n",
        "    - PIX\n",
        "    - Boleto bancário\n",
        "    - PayPal\n",
        "\n",
        "    PRAZOS DE ENTREGA:\n",
        "    - Região Sudeste: 3-5 dias úteis\n",
        "    - Região Sul: 5-7 dias úteis\n",
        "    - Região Nordeste: 7-10 dias úteis\n",
        "    - Região Norte/Centro-Oeste: 10-15 dias úteis\n",
        "    \"\"\"\n",
        "\n",
        "    # Salvar base de conhecimento em arquivo temporário\n",
        "    with open(\"knowledge_base.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(knowledge_content)\n",
        "\n",
        "    # Carregar base de conhecimento\n",
        "    agent.load_knowledge_base(\"knowledge_base.txt\")\n",
        "\n",
        "    print(\"=== AGENTE DE ATENDIMENTO INICIADO ===\")\n",
        "    print(\"Digite 'sair' para encerrar ou 'reset' para reiniciar a conversa\\n\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"Cliente: \")\n",
        "\n",
        "        if user_input.lower() == 'sair':\n",
        "            break\n",
        "        elif user_input.lower() == 'reset':\n",
        "            agent.reset_conversation()\n",
        "            print(\"Conversa reiniciada!\\n\")\n",
        "            continue\n",
        "\n",
        "        response = agent.chat(user_input)\n",
        "        print(f\"Atendente: {response}\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "# %%\n",
        "import os\n",
        "import logging\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Optional\n",
        "from dataclasses import dataclass\n",
        "\n",
        "# Update imports based on potential LangChain refactor\n",
        "# from langchain.chat_models import ChatOpenAI # Old import\n",
        "from langchain_community.chat_models import ChatOpenAI # New import\n",
        "\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
        "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
        "from langchain.tools import Tool\n",
        "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "# Update imports based on potential LangChain refactor\n",
        "# from langchain.vectorstores import FAISS # Old import\n",
        "# from langchain.embeddings import OpenAIEmbeddings # Old import\n",
        "# from langchain.document_loaders import TextLoader # Old import\n",
        "# from langchain.text_splitter import RecursiveCharacterTextSplitter # Old import\n",
        "from langchain_community.vectorstores import FAISS # New import\n",
        "from langchain_community.embeddings import OpenAIEmbeddings # New import\n",
        "from langchain_community.document_loaders import TextLoader # New import\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "\n",
        "# Configuração de logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "@dataclass\n",
        "class CustomerInfo:\n",
        "    \"\"\"Informações do cliente\"\"\"\n",
        "    customer_id: str\n",
        "    name: str\n",
        "    email: str\n",
        "    phone: str\n",
        "    tier: str  # \"bronze\", \"silver\", \"gold\", \"platinum\"\n",
        "\n",
        "class KnowledgeBase:\n",
        "    \"\"\"Base de conhecimento para consultas\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.vectorstore = None\n",
        "        self.embeddings = OpenAIEmbeddings()\n",
        "\n",
        "    def load_knowledge_base(self, file_path: str):\n",
        "        \"\"\"Carrega a base de conhecimento de um arquivo\"\"\"\n",
        "        try:\n",
        "            loader = TextLoader(file_path, encoding='utf-8')\n",
        "            documents = loader.load()\n",
        "\n",
        "            text_splitter = RecursiveCharacterTextSplitter(\n",
        "                chunk_size=1000,\n",
        "                chunk_overlap=200\n",
        "            )\n",
        "            texts = text_splitter.split_documents(documents)\n",
        "\n",
        "            self.vectorstore = FAISS.from_documents(texts, self.embeddings)\n",
        "            logger.info(f\"Base de conhecimento carregada com {len(texts)} documentos\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Erro ao carregar base de conhecimento: {e}\")\n",
        "\n",
        "    def search(self, query: str, k: int = 3) -> List[str]:\n",
        "        \"\"\"Busca informações na base de conhecimento\"\"\"\n",
        "        if not self.vectorstore:\n",
        "            return [\"Base de conhecimento não carregada\"]\n",
        "\n",
        "        try:\n",
        "            docs = self.vectorstore.similarity_search(query, k=k)\n",
        "            return [doc.page_content for doc in docs]\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Erro na busca: {e}\")\n",
        "            return [\"Erro ao buscar informações\"]\n",
        "\n",
        "class CustomerServiceAgent:\n",
        "    \"\"\"Agente de atendimento ao cliente com LangChain\"\"\"\n",
        "\n",
        "    def __init__(self, openai_api_key: str):\n",
        "        os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "\n",
        "        # Inicializar componentes\n",
        "        self.llm = ChatOpenAI(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            temperature=0.7,\n",
        "            max_tokens=500\n",
        "        )\n",
        "\n",
        "        self.memory = ConversationBufferWindowMemory(\n",
        "            k=10,\n",
        "            memory_key=\"chat_history\",\n",
        "            return_messages=True\n",
        "        )\n",
        "\n",
        "        self.knowledge_base = KnowledgeBase()\n",
        "        self.current_customer: Optional[CustomerInfo] = None\n",
        "\n",
        "        # Configurar ferramentas\n",
        "        self.tools = self._create_tools()\n",
        "\n",
        "        # Configurar prompt do agente\n",
        "        self.prompt = self._create_prompt()\n",
        "\n",
        "        # Criar agente\n",
        "        self.agent = create_openai_functions_agent(\n",
        "            llm=self.llm,\n",
        "            tools=self.tools,\n",
        "            prompt=self.prompt\n",
        "        )\n",
        "\n",
        "        self.agent_executor = AgentExecutor(\n",
        "            agent=self.agent,\n",
        "            tools=self.tools,\n",
        "            memory=self.memory,\n",
        "            verbose=True,\n",
        "            max_iterations=3\n",
        "        )\n",
        "\n",
        "    def _create_tools(self) -> List[Tool]:\n",
        "        \"\"\"Cria as ferramentas disponíveis para o agente\"\"\"\n",
        "\n",
        "        def search_knowledge_base(query: str) -> str:\n",
        "            \"\"\"Busca informações na base de conhecimento\"\"\"\n",
        "            results = self.knowledge_base.search(query)\n",
        "            return \"\\n\\n\".join(results)\n",
        "\n",
        "        def get_customer_info(customer_id: str) -> str:\n",
        "            \"\"\"Obtém informações do cliente\"\"\"\n",
        "            # Simulação - em produção seria uma consulta ao banco de dados\n",
        "            customers_db = {\n",
        "                \"12345\": CustomerInfo(\"12345\", \"João Silva\", \"joao@email.com\", \"(11) 99999-9999\", \"gold\"),\n",
        "                \"67890\": CustomerInfo(\"67890\", \"Maria Santos\", \"maria@email.com\", \"(11) 88888-8888\", \"silver\")\n",
        "            }\n",
        "\n",
        "            customer = customers_db.get(customer_id)\n",
        "            if customer:\n",
        "                self.current_customer = customer\n",
        "                return f\"Cliente: {customer.name}\\nEmail: {customer.email}\\nTelefone: {customer.phone}\\nNível: {customer.tier}\"\n",
        "            return \"Cliente não encontrado\"\n",
        "\n",
        "        def escalate_to_human(reason: str) -> str:\n",
        "            \"\"\"Escala o atendimento para um atendente humano\"\"\"\n",
        "            logger.info(f\"Escalação solicitada: {reason}\")\n",
        "            return f\"Atendimento escalado para humano. Motivo: {reason}. Um atendente entrará em contato em breve.\"\n",
        "\n",
        "        def check_order_status(order_id: str) -> str:\n",
        "            \"\"\"Consulta status do pedido\"\"\"\n",
        "            # Simulação - em produção seria uma consulta ao sistema de pedidos\n",
        "            orders_db = {\n",
        "                \"ORD001\": {\"status\": \"Em trânsito\", \"tracking\": \"BR123456789\", \"delivery_date\": \"2024-01-15\"},\n",
        "                \"ORD002\": {\"status\": \"Entregue\", \"tracking\": \"BR987654321\", \"delivery_date\": \"2024-01-10\"}\n",
        "            }\n",
        "\n",
        "            order = orders_db.get(order_id)\n",
        "            if order:\n",
        "                return f\"Pedido {order_id}: {order['status']}\\nCódigo de rastreamento: {order['tracking']}\\nPrevisão de entrega: {order['delivery_date']}\"\n",
        "            return \"Pedido não encontrado\"\n",
        "\n",
        "        return [\n",
        "            Tool(\n",
        "                name=\"search_knowledge_base\",\n",
        "                description=\"Busca informações na base de conhecimento da empresa\",\n",
        "                func=search_knowledge_base\n",
        "            ),\n",
        "            Tool(\n",
        "                name=\"get_customer_info\",\n",
        "                description=\"Obtém informações do cliente usando o ID do cliente\",\n",
        "                func=get_customer_info\n",
        "            ),\n",
        "            Tool(\n",
        "                name=\"escalate_to_human\",\n",
        "                description=\"Escala o atendimento para um atendente humano quando necessário\",\n",
        "                func=escalate_to_human\n",
        "            ),\n",
        "            Tool(\n",
        "                name=\"check_order_status\",\n",
        "                description=\"Consulta o status de um pedido usando o ID do pedido\",\n",
        "                func=check_order_status\n",
        "            )\n",
        "        ]\n",
        "\n",
        "    def _create_prompt(self) -> ChatPromptTemplate:\n",
        "        \"\"\"Cria o prompt do agente\"\"\"\n",
        "        system_message = \"\"\"Você é um assistente virtual de atendimento ao cliente altamente qualificado e empático.\n",
        "\n",
        "INSTRUÇÕES:\n",
        "- Seja sempre cordial, profissional e prestativo\n",
        "- Use linguagem clara e acessível\n",
        "- Mantenha o foco na resolução do problema do cliente\n",
        "- Se não souber a resposta, use as ferramentas disponíveis ou escale para um humano\n",
        "- Sempre confirme informações importantes com o cliente\n",
        "- Personalize o atendimento baseado no perfil do cliente\n",
        "\n",
        "QUANDO ESCALAR PARA HUMANO:\n",
        "- Reclamações complexas ou sensíveis\n",
        "- Solicitações de reembolso acima de R$ 500\n",
        "- Problemas técnicos que não consegue resolver\n",
        "- Cliente expressamente solicita falar com humano\n",
        "- Situações que exigem tomada de decisão gerencial\n",
        "\n",
        "FERRAMENTAS DISPONÍVEIS:\n",
        "- search_knowledge_base: Para buscar informações sobre produtos, políticas, etc.\n",
        "- get_ customer_info: Para obter dados do cliente\n",
        "- escalate_to_human: Para transferir para atendente humano\n",
        "- check_order_status: Para consultar status de pedidos\n",
        "\n",
        "Hora atual: {current_time}\n",
        "\"\"\"\n",
        "\n",
        "        return ChatPromptTemplate.from_messages([\n",
        "            (\"system\", system_message),\n",
        "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "            (\"human\", \"{input}\"),\n",
        "            MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
        "        ])\n",
        "\n",
        "    def load_knowledge_base(self, file_path: str):\n",
        "        \"\"\"Carrega a base de conhecimento\"\"\"\n",
        "        self.knowledge_base.load_knowledge_base(file_path)\n",
        "\n",
        "    def chat(self, message: str) -> str:\n",
        "        \"\"\"Processa uma mensagem do cliente\"\"\"\n",
        "        try:\n",
        "            current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "            # Adiciona contexto do cliente se disponível\n",
        "            context = \"\"\n",
        "            if self.current_customer:\n",
        "                context = f\"\\nCliente atual: {self.current_customer.name} (Nível: {self.current_customer.tier})\"\n",
        "\n",
        "            response = self.agent_executor.invoke({\n",
        "                \"input\": message + context,\n",
        "                \"current_time\": current_time\n",
        "            })\n",
        "\n",
        "            return response[\"output\"]\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Erro no processamento: {e}\")\n",
        "            return \"Desculpe, ocorreu um erro interno. Vou transferir você para um atendente humano.\"\n",
        "\n",
        "    def reset_conversation(self):\n",
        "        \"\"\"Reinicia a conversa\"\"\"\n",
        "        self.memory.clear()\n",
        "        self.current_customer = None\n",
        "        logger.info(\"Conversa reiniciada\")\n",
        "\n",
        "# Exemplo de uso\n",
        "def main():\n",
        "    # Configurar chave da API OpenAI\n",
        "    API_KEY = \"sua-chave-openai-aqui\"\n",
        "\n",
        "    # Criar agente\n",
        "    agent = CustomerServiceAgent(API_KEY)\n",
        "\n",
        "    # Exemplo de base de conhecimento (criar arquivo knowledge_base.txt)\n",
        "    knowledge_content = \"\"\"\n",
        "    POLÍTICA DE TROCA E DEVOLUÇÃO:\n",
        "    - Prazo: 30 dias corridos a partir da data de recebimento\n",
        "    - Produto deve estar em perfeitas condições\n",
        "    - Embalagem original deve estar preservada\n",
        "    - Taxa de reenvio por conta do cliente (exceto defeito de fabricação)\n",
        "\n",
        "    FORMAS DE PAGAMENTO ACEITAS:\n",
        "    - Cartão de crédito (Visa, Mastercard, Elo)\n",
        "    - Cartão de débito\n",
        "    - PIX\n",
        "    - Boleto bancário\n",
        "    - PayPal\n",
        "\n",
        "    PRAZOS DE ENTREGA:\n",
        "    - Região Sudeste: 3-5 dias úteis\n",
        "    - Região Sul: 5-7 dias úteis\n",
        "    - Região Nordeste: 7-10 dias úteis\n",
        "    - Região Norte/Centro-Oeste: 10-15 dias úteis\n",
        "    \"\"\"\n",
        "\n",
        "    # Salvar base de conhecimento em arquivo temporário\n",
        "    with open(\"knowledge_base.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(knowledge_content)\n",
        "\n",
        "    # Carregar base de conhecimento\n",
        "    agent.load_knowledge_base(\"knowledge_base.txt\")\n",
        "\n",
        "    print(\"=== AGENTE DE ATENDIMENTO INICIADO ===\")\n",
        "    print(\"Digite 'sair' para encerrar ou 'reset' para reiniciar a conversa\\n\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"Cliente: \")\n",
        "\n",
        "        if user_input.lower() == 'sair':\n",
        "            break\n",
        "        elif user_input.lower() == 'reset':\n",
        "            agent.reset_conversation()\n",
        "            print(\"Conversa reiniciada!\\n\")\n",
        "            continue\n",
        "\n",
        "        response = agent.chat(user_input)\n",
        "        print(f\"Atendente: {response}\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "vdgxAmq1gguH",
        "outputId": "a27b1548-8d90-4ccc-bcb7-0b6f33eb44fa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain_community'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2592413777>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Update imports based on potential LangChain refactor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# from langchain.chat_models import ChatOpenAI # Old import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_community\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOpenAI\u001b[0m \u001b[0;31m# New import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConversationBufferWindowMemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_community'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-community\n",
        "!pip install langchain-openai # Ensure OpenAI integration is also available in community package\n",
        "\n",
        "import os\n",
        "import logging\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Optional\n",
        "from dataclasses import dataclass\n",
        "\n",
        "# Update imports based on potential LangChain refactor\n",
        "# from langchain.chat_models import ChatOpenAI # Old import\n",
        "from langchain_community.chat_models import ChatOpenAI # New import\n",
        "\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
        "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
        "from langchain.tools import Tool\n",
        "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "# Update imports based on potential LangChain refactor\n",
        "# from langchain.vectorstores import FAISS # Old import\n",
        "# from langchain.embeddings import OpenAIEmbeddings # Old import\n",
        "# from langchain.document_loaders import TextLoader # Old import\n",
        "# from langchain.text_splitter import RecursiveCharacterTextSplitter # Old import\n",
        "from langchain_community.vectorstores import FAISS # New import\n",
        "from langchain_community.embeddings import OpenAIEmbeddings # New import\n",
        "from langchain_community.document_loaders import TextLoader # New import\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "\n",
        "# Configuração de logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "@dataclass\n",
        "class CustomerInfo:\n",
        "    \"\"\"Informações do cliente\"\"\"\n",
        "    customer_id: str\n",
        "    name: str\n",
        "    email: str\n",
        "    phone: str\n",
        "    tier: str  # \"bronze\", \"silver\", \"gold\", \"platinum\"\n",
        "\n",
        "class KnowledgeBase:\n",
        "    \"\"\"Base de conhecimento para consultas\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.vectorstore = None\n",
        "        # Ensure OpenAIEmbeddings is imported from langchain_community\n",
        "        self.embeddings = OpenAIEmbeddings()\n",
        "\n",
        "    def load_knowledge_base(self, file_path: str):\n",
        "        \"\"\"Carrega a base de conhecimento de um arquivo\"\"\"\n",
        "        try:\n",
        "            # Ensure TextLoader is imported from langchain_community\n",
        "            loader = TextLoader(file_path, encoding='utf-8')\n",
        "            documents = loader.load()\n",
        "\n",
        "            text_splitter = RecursiveCharacterTextSplitter(\n",
        "                chunk_size=1000,\n",
        "                chunk_overlap=200\n",
        "            )\n",
        "            texts = text_splitter.split_documents(documents)\n",
        "\n",
        "            # Ensure FAISS is imported from langchain_community\n",
        "            self.vectorstore = FAISS.from_documents(texts, self.embeddings)\n",
        "            logger.info(f\"Base de conhecimento carregada com {len(texts)} documentos\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Erro ao carregar base de conhecimento: {e}\")\n",
        "\n",
        "    def search(self, query: str, k: int = 3) -> List[str]:\n",
        "        \"\"\"Busca informações na base de conhecimento\"\"\"\n",
        "        if not self.vectorstore:\n",
        "            return [\"Base de conhecimento não carregada\"]\n",
        "\n",
        "        try:\n",
        "            # similarity_search is a method of the vectorstore object,\n",
        "            # which was created using FAISS from langchain_community, so this should work.\n",
        "            docs = self.vectorstore.similarity_search(query, k=k)\n",
        "            return [doc.page_content for doc in docs]\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Erro na busca: {e}\")\n",
        "            return [\"Erro ao buscar informações\"]\n",
        "\n",
        "class CustomerServiceAgent:\n",
        "    \"\"\"Agente de atendimento ao cliente com LangChain\"\"\"\n",
        "\n",
        "    def __init__(self, openai_api_key: str):\n",
        "        os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "\n",
        "        # Inicializar componentes\n",
        "        # Ensure ChatOpenAI is imported from langchain_community\n",
        "        self.llm = ChatOpenAI(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            temperature=0.7,\n",
        "            max_tokens=500\n",
        "        )\n",
        "\n",
        "        # ConversationBufferWindowMemory is still in langchain.memory\n",
        "        self.memory = ConversationBufferWindowMemory(\n",
        "            k=10,\n",
        "            memory_key=\"chat_history\",\n",
        "            return_messages=True\n",
        "        )\n",
        "\n",
        "        self.knowledge_base = KnowledgeBase()\n",
        "        self.current_customer: Optional[CustomerInfo] = None\n",
        "\n",
        "        # Configurar ferramentas\n",
        "        self.tools = self._create_tools()\n",
        "\n",
        "        # Configurar prompt do agente\n",
        "        self.prompt = self._create_prompt()\n",
        "\n",
        "        # Criar agente\n",
        "        # create_openai_functions_agent is still in langchain.agents\n",
        "        self.agent = create_openai_functions_agent(\n",
        "            llm=self.llm,\n",
        "            tools=self.tools,\n",
        "            prompt=self.prompt\n",
        "        )\n",
        "\n",
        "        # AgentExecutor is still in langchain.agents\n",
        "        self.agent_executor = AgentExecutor(\n",
        "            agent=self.agent,\n",
        "            tools=self.tools,\n",
        "            memory=self.memory,\n",
        "            verbose=True,\n",
        "            max_iterations=3\n",
        "        )\n",
        "\n",
        "    def _create_tools(self) -> List[Tool]:\n",
        "        \"\"\"Cria as ferramentas disponíveis para o agente\"\"\"\n",
        "\n",
        "        def search_knowledge_base(query: str) -> str:\n",
        "            \"\"\"Busca informações na base de conhecimento\"\"\"\n",
        "            results = self.knowledge_base.search(query)\n",
        "            return \"\\n\\n\".join(results)\n",
        "\n",
        "        def get_customer_info(customer_id: str) -> str:\n",
        "            \"\"\"Obtém informações do cliente\"\"\"\n",
        "            # Simulação - em produção seria uma consulta ao banco de dados\n",
        "            customers_db = {\n",
        "                \"12345\": CustomerInfo(\"12345\", \"João Silva\", \"joao@email.com\", \"(11) 99999-9999\", \"gold\"),\n",
        "                \"67890\": CustomerInfo(\"67890\", \"Maria Santos\", \"maria@email.com\", \"(11) 88888-8888\", \"silver\")\n",
        "            }\n",
        "\n",
        "            customer = customers_db.get(customer_id)\n",
        "            if customer:\n",
        "                self.current_customer = customer\n",
        "                return f\"Cliente: {customer.name}\\nEmail: {customer.email}\\nTelefone: {customer.phone}\\nNível: {customer.tier}\"\n",
        "            return \"Cliente não encontrado\"\n",
        "\n",
        "        def escalate_to_human(reason: str) -> str:\n",
        "            \"\"\"Escala o atendimento para um atendente humano\"\"\"\n",
        "            logger.info(f\"Escalação solicitada: {reason}\")\n",
        "            return f\"Atendimento escalado para humano. Motivo: {reason}. Um atendente entrará em contato em breve.\"\n",
        "\n",
        "        def check_order_status(order_id: str) -> str:\n",
        "            \"\"\"Consulta status do pedido\"\"\"\n",
        "            # Simulação - em produção seria uma consulta ao sistema de pedidos\n",
        "            orders_db = {\n",
        "                \"ORD001\": {\"status\": \"Em trânsito\", \"tracking\": \"BR123456789\", \"delivery_date\": \"2024-01-15\"},\n",
        "                \"ORD002\": {\"status\": \"Entregue\", \"tracking\": \"BR987654321\", \"delivery_date\": \"2024-01-10\"}\n",
        "            }\n",
        "\n",
        "            order = orders_db.get(order_id)\n",
        "            if order:\n",
        "                return f\"Pedido {order_id}: {order['status']}\\nCódigo de rastreamento: {order['tracking']}\\nPrevisão de entrega: {order['delivery_date']}\"\n",
        "            return \"Pedido não encontrado\"\n",
        "\n",
        "        # Tool is still in langchain.tools\n",
        "        return [\n",
        "            Tool(\n",
        "                name=\"search_knowledge_base\",\n",
        "                description=\"Busca informações na base de conhecimento da empresa\",\n",
        "                func=search_knowledge_base\n",
        "            ),\n",
        "            Tool(\n",
        "                name=\"get_customer_info\",\n",
        "                description=\"Obtém informações do cliente usando o ID do cliente\",\n",
        "                func=get_customer_info\n",
        "            ),\n",
        "            Tool(\n",
        "                name=\"escalate_to_human\",\n",
        "                description=\"Escala o atendimento para um atendente humano quando necessário\",\n",
        "                func=escalate_to_human\n",
        "            ),\n",
        "            Tool(\n",
        "                name=\"check_order_status\",\n",
        "                description=\"Consulta o status de um pedido usando o ID do pedido\",\n",
        "                func=check_order_status\n",
        "            )\n",
        "        ]\n",
        "\n",
        "    def _create_prompt(self) -> ChatPromptTemplate:\n",
        "        \"\"\"Cria o prompt do agente\"\"\"\n",
        "        system_message = \"\"\"Você é um assistente virtual de atendimento ao cliente altamente qualificado e empático.\n",
        "\n",
        "INSTRUÇÕES:\n",
        "- Seja sempre cordial, profissional e prestativo\n",
        "- Use linguagem clara e acessível\n",
        "- Mantenha o foco na resolução do problema do cliente\n",
        "- Se não souber a resposta, use as ferramentas disponíveis ou escale para um humano\n",
        "- Sempre confirme informações importantes com o cliente\n",
        "- Personalize o atendimento baseado no perfil do cliente\n",
        "\n",
        "QUANDO ESCALAR PARA HUMANO:\n",
        "- Reclamações complexas ou sensíveis\n",
        "- Solicitações de reembolso acima de R$ 500\n",
        "- Problemas técnicos que não consegue resolver\n",
        "- Cliente expressamente solicita falar com humano\n",
        "- Situações que exigem tomada de decisão gerencial\n",
        "\n",
        "FERRAMENTAS DISPONÍVEIS:\n",
        "- search_knowledge_base: Para buscar informações sobre produtos, políticas, etc.\n",
        "- get_ customer_info: Para obter dados do cliente\n",
        "- escalate_to_human: Para transferir para atendente humano\n",
        "- check_order_status: Para consultar status de pedidos\n",
        "\n",
        "Hora atual: {current_time}\n",
        "\"\"\"\n",
        "        # ChatPromptTemplate and MessagesPlaceholder are still in langchain.prompts\n",
        "        return ChatPromptTemplate.from_messages([\n",
        "            (\"system\", system_message),\n",
        "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "            (\"human\", \"{input}\"),\n",
        "            MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
        "        ])\n",
        "\n",
        "    def load_knowledge_base(self, file_path: str):\n",
        "        \"\"\"Carrega a base de conhecimento\"\"\"\n",
        "        self.knowledge_base.load_knowledge_base(file_path)\n",
        "\n",
        "    def chat(self, message: str) -> str:\n",
        "        \"\"\"Processa uma mensagem do cliente\"\"\"\n",
        "        try:\n",
        "            current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "            # Adiciona contexto do cliente se disponível\n",
        "            context = \"\"\n",
        "            if self.current_customer:\n",
        "                context = f\"\\nCliente atual: {self.current_customer.name} (Nível: {self.current_customer.tier})\"\n",
        "\n",
        "            # The invoke method call looks correct.\n",
        "            response = self.agent_executor.invoke({\n",
        "                \"input\": message + context,\n",
        "                \"current_time\": current_time\n",
        "            })\n",
        "\n",
        "            return response[\"output\"]\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Erro no processamento: {e}\")\n",
        "            return \"Desculpe, ocorreu um erro interno. Vou transferir você para um atendente humano.\"\n",
        "\n",
        "    def reset_conversation(self):\n",
        "        \"\"\"Reinicia a conversa\"\"\"\n",
        "        self.memory.clear()\n",
        "        self.current_customer = None\n",
        "        logger.info(\"Conversa reiniciada\")\n",
        "\n",
        "# Exemplo de uso\n",
        "def main():\n",
        "    # Configurar chave da API OpenAI\n",
        "    # Replace \"sua-chave-openai-aqui\" with your actual OpenAI API key\n",
        "    # Or better, set it as an environment variable before running the script\n",
        "    # os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\"\n",
        "    API_KEY = os.environ.get(\"OPENAI_API_KEY\", \"sua-chave-openai-aqui\")\n",
        "    if API_KEY == \"sua-chave-openai-aqui\":\n",
        "        print(\"ATENÇÃO: Substitua 'sua-chave-openai-aqui' pela sua chave real da API OpenAI ou defina a variável de ambiente OPENAI_API_KEY.\")\n",
        "        # You might want to exit or handle this differently in a real application\n",
        "        # sys.exit(\"Chave da API OpenAI não configurada.\")\n",
        "\n",
        "\n",
        "    # Criar agente\n",
        "    agent = CustomerServiceAgent(API_KEY)\n",
        "\n",
        "    # Exemplo de base de conhecimento (criar arquivo knowledge_base.txt)\n",
        "    knowledge_content = \"\"\"\n",
        "    POLÍTICA DE TROCA E DEVOLUÇÃO:\n",
        "    - Prazo: 30 dias corridos a partir da data de recebimento\n",
        "    - Produto deve estar em perfeitas condições\n",
        "    - Embalagem original deve estar preservada\n",
        "    - Taxa de reenvio por conta do cliente (exceto defeito de fabricação)\n",
        "\n",
        "    FORMAS DE PAGAMENTO ACEITAS:\n",
        "    - Cartão de crédito (Visa, Mastercard, Elo)\n",
        "    - Cartão de débito\n",
        "    - PIX\n",
        "    - Boleto bancário\n",
        "    - PayPal\n",
        "\n",
        "    PRAZOS DE ENTREGA:\n",
        "    - Região Sudeste: 3-5 dias úteis\n",
        "    - Região Sul: 5-7 dias úteis\n",
        "    - Região Nordeste: 7-10 dias úteis\n",
        "    - Região Norte/Centro-Oeste: 10-15 dias úteis\n",
        "    \"\"\"\n",
        "\n",
        "    # Salvar base de conhecimento em arquivo temporário\n",
        "    with open(\"knowledge_base.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(knowledge_content)\n",
        "\n",
        "    # Carregar base de conhecimento\n",
        "    agent.load_knowledge_base(\"knowledge_base.txt\")\n",
        "\n",
        "    print(\"=== AGENTE DE ATENDIMENTO INICIADO ===\")\n",
        "    print(\"Digite 'sair' para encerrar ou 'reset' para reiniciar a conversa\\n\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"Cliente: \")\n",
        "\n",
        "        if user_input.lower() == 'sair':\n",
        "            break\n",
        "        elif user_input.lower() == 'reset':\n",
        "            agent.reset_conversation()\n",
        "            print(\"Conversa reiniciada!\\n\")\n",
        "            continue\n",
        "\n",
        "        response = agent.chat(user_input)\n",
        "        print(f\"Atendente: {response}\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qwj9SbMug1ni",
        "outputId": "e5bef0e5-5350-41c2-952d-cd4465d00692"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.25-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.65 (from langchain-community)\n",
            "  Downloading langchain_core-0.3.65-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.25)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.44)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (2.11.5)\n",
            "Collecting langsmith<0.4,>=0.1.125 (from langchain-community)\n",
            "  Downloading langsmith-0.3.45-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain-community) (4.14.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.65->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.25-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain_core-0.3.65-py3-none-any.whl (438 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.1/438.1 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langsmith-0.3.45-py3-none-any.whl (363 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.0/363.0 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, langsmith, dataclasses-json, langchain-core, langchain-community\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.3.44\n",
            "    Uninstalling langsmith-0.3.44:\n",
            "      Successfully uninstalled langsmith-0.3.44\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.63\n",
            "    Uninstalling langchain-core-0.3.63:\n",
            "      Successfully uninstalled langchain-core-0.3.63\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.25 langchain-core-0.3.65 langsmith-0.3.45 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.9.1 python-dotenv-1.1.0 typing-inspect-0.9.0\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.22-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.64 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.3.65)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.84.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.64->langchain-openai) (0.3.45)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.64->langchain-openai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.64->langchain-openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.64->langchain-openai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.64->langchain-openai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.64->langchain-openai) (4.14.0)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.64->langchain-openai) (2.11.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain-openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.64->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.64->langchain-openai) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.64->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.64->langchain-openai) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.64->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.64->langchain-openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.64->langchain-openai) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.4.0)\n",
            "Downloading langchain_openai-0.3.22-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.3/65.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-openai\n",
            "Successfully installed langchain-openai-0.3.22\n",
            "ATENÇÃO: Substitua 'sua-chave-openai-aqui' pela sua chave real da API OpenAI ou defina a variável de ambiente OPENAI_API_KEY.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-1242874988>:93: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  self.llm = ChatOpenAI(\n",
            "<ipython-input-3-1242874988>:100: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  self.memory = ConversationBufferWindowMemory(\n",
            "<ipython-input-3-1242874988>:49: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
            "  self.embeddings = OpenAIEmbeddings()\n",
            "ERROR:__main__:Erro ao carregar base de conhecimento: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sua-chav*********aqui. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== AGENTE DE ATENDIMENTO INICIADO ===\n",
            "Digite 'sair' para encerrar ou 'reset' para reiniciar a conversa\n",
            "\n",
            "Cliente: qual a politica da empresa\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:__main__:Erro no processamento: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sua-chav*********aqui. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "Atendente: Desculpe, ocorreu um erro interno. Vou transferir você para um atendente humano.\n",
            "\n",
            "Cliente: meu id é or14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:__main__:Erro no processamento: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sua-chav*********aqui. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "Atendente: Desculpe, ocorreu um erro interno. Vou transferir você para um atendente humano.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}